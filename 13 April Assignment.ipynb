{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d661b-c6ff-4ff7-959c-08a97d035d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bfa6b6-34ef-4cd5-9f7e-c533aa98e692",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecba088-7d67-444b-92b1-43bbfa172d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "A random forest regressor is a machine learning algorithm that uses an ensemble of decision trees to perform regression tasks.\n",
    "It fits a number of trees on different sub-samples of the data and averages their predictions to improve accuracy and prevent over-fitting.\n",
    "The sub-sample size and the number of trees can be controlled by parameters. It is a flexible and easy to use technique that can also be \n",
    "used for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97441c07-dd64-433c-b852-8414042347ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8eb47e-70ba-432f-9466-caa8bdf4b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How does Random Forest Regressor reduce the risk of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5fcb51-5a42-4649-9004-eb0cd2b77cb6",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1fe4c-95cb-46d5-96ca-9d52cefbe603",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest Regressor is an ensemble learning method that constructs a multitude of decision trees at training time and outputs \n",
    "the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n",
    "Random Forest Regressor reduces the risk of overfitting by averaging the predictions of multiple decision trees. \n",
    "Decision trees tend to tightly fit all the samples within training data and run the risk of overfitting.\n",
    "However, when there’s a robust number of decision trees in a random forest, the classifier won’t overfit the model since the \n",
    "averaging of uncorrelated trees lowers the overall variance and prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d321fd1-42c7-4505-960e-ea1d10bca891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd5b24d-bc70-40c2-9c8c-8d869541a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75bc90-d64b-4741-8904-9148f2b622ce",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2179633-99c1-435b-9392-9eebca043a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest Regressor aggregates the predictions of multiple decision trees by taking the prediction from each tree and based on \n",
    "the majority votes of predictions. The greater number of trees in the forest leads to higher accuracy and prevents the problem of overfitting.\n",
    "A random forest is a meta-estimator that aggregates many decision trees with some helpful modifications. The number of features that \n",
    "can be split at each node is limited to some percentage of the total, which is known as the hyper-parameter.\n",
    "\n",
    "When using Random Forest for regression, the forest picks the average of the outputs of all trees. The key here lies in the fact that there\n",
    "is low (or no) correlation between the individual models—that is, between the decision trees that make up the larger Random Forest model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c8bccd-e2e4-40ff-ac8b-da730fede187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e14cc51-e643-4703-b385-73374a6fe6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What are the hyperparameters of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cb7945-f452-4de0-a17a-8dd401ae91f9",
   "metadata": {},
   "source": [
    "ANS  -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402248ad-3a98-494a-87d4-f2d1c37fb171",
   "metadata": {},
   "outputs": [],
   "source": [
    "The random forest algorithm has several hyperparameters that have to be set by the user. Some of the hyperparameters are:\n",
    "\n",
    "The number of observations drawn randomly for each tree and whether they are drawn with or without replacement.\n",
    "The number of variables drawn randomly for each split.\n",
    "The splitting rule.\n",
    "The minimum number of samples that a node must contain.\n",
    "The number of trees.\n",
    "You can inspect the hyperparameters of RandomForestRegressor in Python using scikit-learn’s default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d670cbc4-f38a-4d4c-8f34-0a2b69d8acf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5826b1aa-3b71-47cf-819a-148f67e32eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ab2a20-649d-4795-b689-e95fbffdc9ed",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d12e3c7-f789-4328-851b-042d93f5dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest Regression is a kind of ensemble classifier which uses a decision tree algorithm in a randomized fashion and in a \n",
    "randomized way. It consists of different decision trees of different sizes and shapes. It is a machine learning technique that solves\n",
    "the regression and classification problems. On the other hand, Decision Tree Regression is a supervised machine learning algorithm that\n",
    "is used to solve regression and classification problems. It is like a tree-structure with decision nodes, which consist of two or more \n",
    "branches and leaf nodes, which represent a decision, and the top node is the root node1.\n",
    "\n",
    "In Random Forest Regression, each node in the decision tree works on a random subset of features to calculate the output. The random forest\n",
    "then combines the output of individual decision trees to generate the final output.\n",
    "\n",
    "While Decision Trees are easy to interpret because we can create a tree diagram to visualize and understand the final model,\n",
    "we can’t visualize a random forest and it can often be difficult to understand how the final random forest model makes decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4d11a-bb72-444f-ace7-1b9cb710613c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47082e-4b9e-4bed-b5d4-a4f556ef6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. What are the advantages and disadvantages of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da3b40-f4e5-4599-a032-1aa381e7c4a7",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95088d0e-1efa-48ea-bb37-988e044469ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest Regressor is a popular machine learning algorithm that can be used for both classification and regression problems.\n",
    "Here are some advantages and disadvantages of Random Forest Regressor:\n",
    "\n",
    "Advantages:\n",
    "\n",
    "It reduces overfitting in decision trees and helps to improve the accuracy.\n",
    "It is flexible to both classification and regression problems.\n",
    "It works well with both categorical and continuous values.\n",
    "It automates missing values present in the data.\n",
    "Normalising of data is not required as it uses a rule-based approach.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Random Forest Regressor is unable to discover trends that would enable it in extrapolating values that fall outside the training set.\n",
    "When faced with such a scenario, the regressor assumes that the prediction will fall close to the maximum value in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddbe738-21a4-42a7-981c-0a109c47cafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73d97b-da5e-4673-9d39-e3bb02067e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. What is the output of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1198c19-91f7-4aed-b866-d7c386bdc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest Regressor is an ensemble technique capable of performing both regression and classification tasks with the use of\n",
    "multiple decision trees and a technique called Bootstrap and Aggregation, commonly known as bagging⁶. The output of Random Forest Regression\n",
    "is the predicted value of the target variable². The predicted value can be a continuous value (regression) or a categorical value\n",
    "(classification). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb1958-7f23-42cb-9948-30735b2e36de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9286b10-31a8-46b8-b646-8824646b56f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. Can Random Forest Regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e732a4d-b4ef-4866-ba53-9e76e4811d0d",
   "metadata": {},
   "source": [
    "ANS-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d0309-d4ac-4b71-a696-aa69fc1a5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yes, Random Forest Regressor can be used for classification tasks. Random Forest is one of the popular machine-learning algorithms which\n",
    "can be used in classification and regression tasks. The Random Forest algorithm creates many decision trees (a forest) and takes the \n",
    "majority vote out of all the decision trees if it is a classification problem¹. It is flexible and can handle a wide range of data types,\n",
    "including numerical, categorical, and binary data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
